{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import evaluate\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import hf_hub_download\n",
    "from PIL import Image as PImage\n",
    "from torch import nn\n",
    "from transformers import MaskFormerForInstanceSegmentation, MaskFormerImageProcessor\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = [\n",
    "    [120, 120, 120], [4, 200, 4], [180, 120, 120], [6, 230, 230],\n",
    "    [80, 50, 50], [120, 120, 80], [140, 140, 140], [204, 5, 255]\n",
    "]\n",
    "\n",
    "\n",
    "def np_from_tensor(img_t):\n",
    "    return np.moveaxis(img_t.numpy().astype(np.uint8), 0, -1)\n",
    "\n",
    "\n",
    "def add_segmentations_to_image(img, segs):\n",
    "    color_segmentation_map = np.zeros((segs.shape[0], segs.shape[1], 3), dtype=np.uint8)\n",
    "    for label, color in enumerate(palette):\n",
    "        color_segmentation_map[segs == label, :] = color\n",
    "    img_mask = np.array(img) * 0.5 + color_segmentation_map * 0.5\n",
    "    return img_mask.astype(np.uint8)\n",
    "\n",
    "\n",
    "def mask_from_label(masks, labels, label_name):\n",
    "  print(\"Label:\", label_name)\n",
    "  idx = labels.index(label_name)\n",
    "\n",
    "  visual_mask = (masks[idx].bool().numpy() * 255).astype(np.uint8)\n",
    "  return visual_mask\n",
    "\n",
    "\n",
    "def add_mask_label_to_image(img, mask_label, label_idx):\n",
    "    img_mask_label = np.zeros((mask_label.shape[0], mask_label.shape[1], 3), dtype=np.uint8)\n",
    "    img_mask_label[mask_label == 255, :] = palette[label_idx]\n",
    "    img_mask_label = 0.5 * img + 0.5 * img_mask_label\n",
    "    return img_mask_label.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = f\"thiagohersan/satellite-trees\"\n",
    "base_model_id = f\"facebook/maskformer-swin-base-ade\"\n",
    "result_model_id = f\"maskformer-satellite-trees\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = json.load(open(hf_hub_download(dataset_id, \"id2label.json\", repo_type=\"dataset\"), \"r\"))\n",
    "id2label = {int(k):v for k,v in id2label.items()}\n",
    "label2id = {v:int(k) for k,v in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MaskFormerForInstanceSegmentation.from_pretrained(\n",
    "    base_model_id,\n",
    "    id2label=id2label,\n",
    "    ignore_mismatched_sizes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(dataset_id)\n",
    "dataset = dataset.shuffle(seed=101010)\n",
    "dataset = dataset[\"train\"].train_test_split(test_size=0.2)\n",
    "\n",
    "train_ds = dataset[\"train\"]\n",
    "test_ds = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create MaskFormer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = MaskFormerImageProcessor(\n",
    "    ignore_index=0,\n",
    "    reduce_labels=False,\n",
    "    do_resize=False,\n",
    "    do_rescale=False,\n",
    "    do_normalize=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(transform=None):\n",
    "    def apply_transform(batch_in):\n",
    "        if transform is not None:\n",
    "            img_labels = zip(batch_in[\"pixel_values\"], batch_in[\"label\"])\n",
    "            aug_img_labels = [transform(image=np.array(x), mask=np.array(y)) for x,y in img_labels]\n",
    "            images = [aug[\"image\"] for aug in aug_img_labels]\n",
    "            labels = [aug[\"mask\"] for aug in aug_img_labels]\n",
    "        else:\n",
    "            images = [np.array(x) for x in batch_in[\"pixel_values\"]]\n",
    "            labels = [np.array(x) for x in batch_in[\"label\"]]\n",
    "\n",
    "        batch_out = preprocessor(images=images, segmentation_maps=labels, return_tensors=\"pt\")\n",
    "        return batch_out\n",
    "    return apply_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.CLAHE(),\n",
    "    A.RandomRotate90(),\n",
    "    A.Transpose(),\n",
    "    A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.50, rotate_limit=45, p=.75),\n",
    "    A.Blur(blur_limit=3),\n",
    "    A.OpticalDistortion(),\n",
    "    A.GridDistortion(),\n",
    "    A.HueSaturationValue(),\n",
    "])\n",
    "\n",
    "# train_ds.set_transform(get_transform(train_transform))\n",
    "train_ds.set_transform(get_transform())\n",
    "test_ds.set_transform(get_transform())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = train_ds[0]\n",
    "\n",
    "for k,v in example.items():\n",
    "  try:\n",
    "    print(k,v.shape)\n",
    "  except:\n",
    "    print(f\"{k}[0]\",v[0].shape)\n",
    "\n",
    "ex_labels = [id2label[label] for label in example[\"class_labels\"].tolist()]\n",
    "print(ex_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PImage.fromarray(np_from_tensor(example['pixel_values']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PImage.fromarray(mask_from_label(example[\"mask_labels\"], ex_labels, 'tree'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PImage.fromarray(\n",
    "    add_mask_label_to_image(\n",
    "        np_from_tensor(example['pixel_values']),\n",
    "        mask_from_label(example[\"mask_labels\"], ex_labels, 'tree'),\n",
    "        ex_labels.index('tree')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"{result_model_id}-outputs\",\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=50,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    save_total_limit=3,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=20,\n",
    "    eval_steps=20,\n",
    "    logging_steps=1,\n",
    "    eval_accumulation_steps=5,\n",
    "    remove_unused_columns=False,\n",
    "    report_to=\"tensorboard\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=True,\n",
    "    hub_model_id=result_model_id,\n",
    "    hub_strategy=\"end\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"mean_iou\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "  print(\"hello\")\n",
    "  print(eval_pred)\n",
    "  with torch.no_grad():\n",
    "    logits, labels = eval_pred\n",
    "    logits_tensor = torch.from_numpy(logits)\n",
    "\n",
    "    # scale the logits to the size of the label\n",
    "    logits_tensor = nn.functional.interpolate(\n",
    "        logits_tensor,\n",
    "        size=labels.shape[-2:],\n",
    "        mode=\"bilinear\",\n",
    "        align_corners=False,\n",
    "    ).argmax(dim=1)\n",
    "\n",
    "    pred_labels = logits_tensor.detach().cpu().numpy()\n",
    "    metrics = metric._compute(\n",
    "            predictions=pred_labels,\n",
    "            references=labels,\n",
    "            num_labels=len(id2label),\n",
    "            ignore_index=0,\n",
    "            reduce_labels=False)\n",
    "\n",
    "    # add per category metrics as individual key-value pairs\n",
    "    per_category_accuracy = metrics.pop(\"per_category_accuracy\").tolist()\n",
    "    per_category_iou = metrics.pop(\"per_category_iou\").tolist()\n",
    "\n",
    "    metrics.update({f\"accuracy_{id2label[i]}\": v for i, v in enumerate(per_category_accuracy)})\n",
    "    metrics.update({f\"iou_{id2label[i]}\": v for i, v in enumerate(per_category_iou)})\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('hf-model')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89e384cab7c47fb35ec95d2248b519cf922ee174880eed636c26cdfb6c4df768"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
