{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import hf_hub_download\n",
    "from PIL import Image as PImage\n",
    "from torch import nn\n",
    "from torchvision import transforms as T\n",
    "from transformers import MaskFormerForInstanceSegmentation, MaskFormerImageProcessor\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ade_mean=[0.485, 0.456, 0.406]\n",
    "ade_std=[0.229, 0.224, 0.225]\n",
    "\n",
    "palette = [\n",
    "    [120, 120, 120], [4, 200, 4], [180, 120, 120], [6, 230, 230],\n",
    "    [80, 50, 50], [120, 120, 80], [140, 140, 140], [204, 5, 255]\n",
    "]\n",
    "\n",
    "\n",
    "def np_from_tensor(img_t, mean=[0.,0.,0.], std=[1.,1.,1.]):\n",
    "    img_t = (img_t * np.array(std)[:, None, None]) + np.array(mean)[:, None, None]\n",
    "    return np.moveaxis((255 * img_t).numpy().astype(np.uint8), 0, -1)\n",
    "\n",
    "\n",
    "def mask_from_label(masks, labels, label_name):\n",
    "  print(\"Label:\", label_name)\n",
    "  idx = labels.index(label_name)\n",
    "\n",
    "  visual_mask = (masks[idx].bool().numpy() * 255).astype(np.uint8)\n",
    "  return visual_mask\n",
    "\n",
    "\n",
    "def add_mask_label_to_image(img, mask_label, label_idx):\n",
    "    img_mask_label = np.zeros((mask_label.shape[0], mask_label.shape[1], 3), dtype=np.uint8)\n",
    "    img_mask_label[mask_label == 255, :] = palette[label_idx]\n",
    "    img_mask_label = 0.5 * img + 0.5 * img_mask_label\n",
    "    return img_mask_label.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = f\"thiagohersan/satellite-trees\"\n",
    "base_model_id = f\"facebook/maskformer-swin-base-ade\"\n",
    "result_model_id = f\"maskformer-satellite-trees\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = json.load(open(hf_hub_download(dataset_id, \"id2label.json\", repo_type=\"dataset\"), \"r\"))\n",
    "id2label = {int(k):v for k,v in id2label.items()}\n",
    "label2id = {v:int(k) for k,v in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MaskFormerForInstanceSegmentation.from_pretrained(\n",
    "    base_model_id,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(dataset_id)\n",
    "dataset = dataset[\"train\"].train_test_split(test_size=0.2, shuffle=True, seed=1010)\n",
    "\n",
    "train_ds = dataset[\"train\"]\n",
    "test_ds = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create MaskFormer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = MaskFormerImageProcessor(\n",
    "    ignore_index=255,\n",
    "    reduce_labels=False,\n",
    "    do_resize=False,\n",
    "    do_rescale=False,\n",
    "    do_normalize=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(transform):\n",
    "    def apply_transform(batch_in):\n",
    "        images = [transform(img) for img in batch_in[\"pixel_values\"]]\n",
    "        labels = [l for l in batch_in[\"label\"]]\n",
    "\n",
    "        batch_out = preprocessor(images=images, segmentation_maps=labels, return_tensors=\"pt\")\n",
    "        return batch_out\n",
    "    return apply_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = T.Compose([\n",
    "    T.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.25),\n",
    "    T.RandomPosterize(bits=2, p=0.2),\n",
    "    T.RandomAdjustSharpness(sharpness_factor=3, p=0.2),\n",
    "    T.RandomAutocontrast(p=0.3),\n",
    "    T.RandomEqualize(p=0.3),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=ade_mean, std=ade_std)\n",
    "])\n",
    "\n",
    "test_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=ade_mean, std=ade_std)\n",
    "])\n",
    "\n",
    "train_ds.set_transform(get_transform(train_transform))\n",
    "test_ds.set_transform(get_transform(test_transform))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = train_ds[0]\n",
    "\n",
    "for k,v in example.items():\n",
    "  try:\n",
    "    print(k,v.shape, v.dtype)\n",
    "  except:\n",
    "    print(f\"{k}[0]\",v[0].shape)\n",
    "\n",
    "ex_labels = [id2label[label] for label in example[\"class_labels\"].tolist()]\n",
    "print(ex_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PImage.fromarray(np_from_tensor(example['pixel_values']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PImage.fromarray(mask_from_label(example[\"mask_labels\"], ex_labels, 'tree'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PImage.fromarray(\n",
    "    add_mask_label_to_image(\n",
    "        np_from_tensor(example['pixel_values']),\n",
    "        mask_from_label(example[\"mask_labels\"], ex_labels, 'tree'),\n",
    "        1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"{result_model_id}-outputs\",\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    save_total_limit=3,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=20,\n",
    "    eval_steps=20,\n",
    "    logging_steps=1,\n",
    "    eval_accumulation_steps=5,\n",
    "    remove_unused_columns=False,\n",
    "    report_to=\"tensorboard\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=True,\n",
    "    hub_model_id=result_model_id,\n",
    "    hub_strategy=\"end\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"mean_iou\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "  print(\"hello\")\n",
    "  print(eval_pred)\n",
    "  with torch.no_grad():\n",
    "    logits, labels = eval_pred\n",
    "    logits_tensor = torch.from_numpy(logits)\n",
    "\n",
    "    # scale the logits to the size of the label\n",
    "    logits_tensor = nn.functional.interpolate(\n",
    "        logits_tensor,\n",
    "        size=labels.shape[-2:],\n",
    "        mode=\"bilinear\",\n",
    "        align_corners=False,\n",
    "    ).argmax(dim=1)\n",
    "\n",
    "    pred_labels = logits_tensor.detach().cpu().numpy()\n",
    "    metrics = metric._compute(\n",
    "            predictions=pred_labels,\n",
    "            references=labels,\n",
    "            num_labels=len(id2label),\n",
    "            ignore_index=255,\n",
    "            reduce_labels=False)\n",
    "\n",
    "    # add per category metrics as individual key-value pairs\n",
    "    per_category_accuracy = metrics.pop(\"per_category_accuracy\").tolist()\n",
    "    per_category_iou = metrics.pop(\"per_category_iou\").tolist()\n",
    "\n",
    "    metrics.update({f\"accuracy_{id2label[i]}\": v for i, v in enumerate(per_category_accuracy)})\n",
    "    metrics.update({f\"iou_{id2label[i]}\": v for i, v in enumerate(per_category_iou)})\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('hf-model')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89e384cab7c47fb35ec95d2248b519cf922ee174880eed636c26cdfb6c4df768"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
